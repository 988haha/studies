深度学习
===
<!--info
toc_id: dl
-->

<!-- TOC -->
- [基础](#基础)
- [模型](#模型)
    - [CNN](#cnn)
    - [RNN](#rnn)
    - [Attention](#attention)
    - [Transformers](#transformers)
- [专题](#专题)
    - [编程框架](#编程框架)
    - [表示学习](#表示学习)
    - [迁移学习](#迁移学习)
    - [不平衡学习](#不平衡学习)
<!-- TOC -->

---

## 基础
- [激活函数](./_archives/2022/05/激活函数.md)
- [损失函数](./_archives/2022/05/损失函数.md)
- [过拟合与正则化](./_archives/2022/05/过拟合与正则化.md)
- [使用爱因斯坦标记法操作张量](./_archives/2022/05/使用爱因斯坦标记法操作张量.md)


## 模型

### CNN
- [CNN基础](./_archives/2022/05/CNN.md)

### RNN
- [RNN基础](./_archives/2022/05/RNN.md)

### Attention
- [常见的Attention计算方法](./_archives/2022/05/Attention.md)

### Transformers
- [Transformer基础](./_archives/2022/05/Transformer.md)
    - [常见面试问题](./_archives/2022/05/Transformer常见面试问题.md)
    - [常见特征提取器的比较（Transformer与CNN、RNN的区别）](./_archives/2022/05/常见特征提取器的比较.md)
- [CRF在神经网络模型中的作用（BERT+CRF）](./_archives/2022/05/CRF在神经网络模型中的作用.md)


## 专题

### 编程框架
> [深度学习编程](./_archives/2022/07/深度学习编程.md)

### 表示学习
- [Sentence-BERT相关问题整理](./_archives/2022/05/Sentence-BERT论文笔记.md)
- [基于**对比学习**的训练框架](./_archives/2022/05/基于对比学习的表示学习训练框架.md)
- [支持**向后兼容**的表示学习](./_archives/2022/05/向后兼容的表示学习.md)
- [基于**互信息**的表示学习](./_archives/2022/05/基于互信息的表示学习.md)（TODO）

### 迁移学习
- [预训练模型的**轻量化微调**方法](./_archives/2022/05/预训练模型轻量化微调.md)

### 不平衡学习
- [不平衡学习概述](./_archives/2022/05/不平衡学习概述.md)
    - [综述-2019-Johnson](./_archives/2022/05/综述-2019-Johnson.md)
        > 介绍了目前在深度学习中常用的不平衡学习方法，主要包括从数据角度和算法角度提出的方法；
- 论文精读
    - [论文-2022-YiboYang](./_archives/2022/05/论文-2022-YiboYang.md)
        > 基于“神经坍缩”现象，使用**等角紧框架**向量初始化分类头且不参与训练，以缓解不平衡问题

